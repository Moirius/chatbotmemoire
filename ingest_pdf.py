# ingest_pdf.py ‚Äî version optimis√©e

import os
from dotenv import load_dotenv
from tqdm import tqdm

from langchain_community.document_loaders import PyPDFLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_openai import OpenAIEmbeddings
from langchain_community.vectorstores import FAISS

# Chargement des variables d'environnement
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

if not openai_api_key:
    raise ValueError("‚ùå Cl√© API OpenAI non trouv√©e. V√©rifie ton fichier .env")

FILE_PATH = "M√©moire Marius Biotteau.pdf"
FAISS_INDEX_PATH = "faiss_index"

def load_and_split_pdf(file_path):
    print("üìÑ Lecture du fichier Markdown...")
    loader = PyPDFLoader(file_path)
    raw_docs = loader.load()

    print("‚úÇÔ∏è D√©coupage en chunks (1500 chars, overlap 200)...")
    splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=150)
    docs = splitter.split_documents(raw_docs)

    print(f"‚úÖ {len(docs)} chunks g√©n√©r√©s.")

    # DEBUG : voir les 3 premiers chunks
    print("\nüß™ Aper√ßu de quelques chunks :")
    for i, doc in enumerate(docs[:3]):
        print(f"\n--- Chunk {i+1} ---\n{doc.page_content[:1000]}\n[...]")

    return docs

def create_faiss_index(docs):
    print("üß† G√©n√©ration des embeddings...")
    embeddings = OpenAIEmbeddings(openai_api_key=openai_api_key)
    vectorstore = FAISS.from_documents(docs, embeddings)

    if os.path.exists(FAISS_INDEX_PATH):
        print("‚ö†Ô∏è Ancien index d√©tect√©. Suppression...")
        import shutil
        shutil.rmtree(FAISS_INDEX_PATH)

    vectorstore.save_local(FAISS_INDEX_PATH)
    print(f"‚úÖ Index FAISS sauvegard√© dans : {FAISS_INDEX_PATH}")

def main():
    docs = load_and_split_pdf(FILE_PATH)
    create_faiss_index(docs)

if __name__ == "__main__":
    main()
